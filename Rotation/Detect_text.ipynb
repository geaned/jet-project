{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "mWSGGP3bwMGU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mWSGGP3bwMGU",
    "outputId": "8ac6fffa-4ab4-488f-8e5b-a3e2c1d15e8d"
   },
   "outputs": [],
   "source": [
    "#!pip install segmentation_models_pytorch\n",
    "#!pip install --upgrade albumentations\n",
    "#!pip uninstall opencv-python-headless==4.5.5.62\n",
    "#!pip install opencv-python-headless==4.5.2.52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b84fa2c",
   "metadata": {
    "id": "5b84fa2c"
   },
   "outputs": [],
   "source": [
    "import json, os\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset as BaseDataset\n",
    "\n",
    "import albumentations as albu\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "o9pgIm6e04wy",
   "metadata": {
    "id": "o9pgIm6e04wy"
   },
   "outputs": [],
   "source": [
    "def get_validation_augmentation():\n",
    "    \"\"\"Add paddings to make image shape divisible by 32\"\"\"\n",
    "    test_transform = [\n",
    "        albu.Resize(640, 640, always_apply=True)\n",
    "    ]\n",
    "    return albu.Compose(test_transform)\n",
    "\n",
    "def to_tensor(x, **kwargs):\n",
    "    return x.transpose(2, 0, 1).astype('float32')\n",
    "\n",
    "def get_preprocessing(preprocessing_fn):    \n",
    "    _transform = [\n",
    "        albu.Lambda(image=preprocessing_fn),\n",
    "        albu.Lambda(image=to_tensor, mask=to_tensor),\n",
    "    ]\n",
    "    return albu.Compose(_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b89a4502",
   "metadata": {
    "id": "b89a4502"
   },
   "outputs": [],
   "source": [
    "class SegmDataset(BaseDataset):\n",
    "    def __init__(self, data_dir, ann_folder='ann', img_folder='img', mask_folder='masks_machine',\n",
    "                augmentation=None, preprocessing=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.ann_folder = ann_folder\n",
    "        self.img_folder = img_folder\n",
    "        self.mask_folder = mask_folder\n",
    "        self.photo_ids = self.extract_ids()\n",
    "        \n",
    "        self.images = [os.path.join(data_dir, img_folder, img + '.png') for img in self.photo_ids]\n",
    "        self.masks = [os.path.join(data_dir, mask_folder, img + '.png') for img in self.photo_ids]\n",
    "        \n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "        \n",
    "    def extract_ids(self):\n",
    "        marked_files = []\n",
    "        ann_files = os.listdir(os.path.join(self.data_dir, self.ann_folder))\n",
    "        for fname in ann_files:\n",
    "            with open(os.path.join(self.data_dir, self.ann_folder, fname), 'r') as json_file:\n",
    "                data = json.load(json_file)\n",
    "                if data['objects']:\n",
    "                    marked_files.append(fname.split('.')[0])\n",
    "        return marked_files\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.photo_ids)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        # read data\n",
    "        image = cv2.imread(self.images[i])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.imread(self.masks[i], 0)\n",
    "        mask = mask[:, :, np.newaxis]\n",
    "        \n",
    "        # apply augmentations\n",
    "        if self.augmentation:\n",
    "            sample = self.augmentation(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "        \n",
    "        # apply preprocessing\n",
    "        if self.preprocessing:\n",
    "            sample = self.preprocessing(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "            \n",
    "        return image, mask        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99941084",
   "metadata": {
    "id": "99941084"
   },
   "outputs": [],
   "source": [
    "train_ann_folder = 'ann'\n",
    "test_ann_folder = train_ann_folder\n",
    "ENCODER = 'resnet34' # resnet18\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7bb2a01",
   "metadata": {
    "id": "e7bb2a01"
   },
   "outputs": [],
   "source": [
    "MODEL_PATH = './td_model/_ocr_model.pth'\n",
    "model = torch.load(MODEL_PATH, map_location=torch.device(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05993511",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "05993511",
    "outputId": "5ad3a62f-798d-4915-acb1-c4ca7cdf2941"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './cropped/good/ann'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12163/3597244736.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m dataset_predict = SegmDataset(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m#\"/storage/smalldata/ocr/ocr_rods_v2/ocr_rods_v2/train\",\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m\"./cropped/good\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_12163/3681250178.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_dir, ann_folder, img_folder, mask_folder, augmentation, preprocessing)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphoto_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.png'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphoto_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_12163/3681250178.py\u001b[0m in \u001b[0;36mextract_ids\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextract_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mmarked_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mann_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mann_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mann_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mann_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './cropped/good/ann'"
     ]
    }
   ],
   "source": [
    "INPUT_DATASET = './cropped/good'\n",
    "PREDICTED = './cropped/good/pred'\n",
    "\n",
    "p = 0.5\n",
    "\n",
    "dataset_predict = SegmDataset(\n",
    "    INPUT_DATASET,\n",
    "    test_ann_folder, \n",
    "    augmentation=get_validation_augmentation(), \n",
    "    preprocessing=get_preprocessing(preprocessing_fn)\n",
    ")\n",
    "\n",
    "for img_path in dataset_predict.images:\n",
    "    img = preprocessing_fn(plt.imread(img_path))\n",
    "    image = get_validation_augmentation()(image=img)['image']\n",
    "    x_tensor = torch.from_numpy(image).to(DEVICE).unsqueeze(0)\n",
    "    x_tensor = x_tensor.permute(0, 3, 1,2)\n",
    "    x_tensor = x_tensor.to(torch.float32)\n",
    "\n",
    "    pr_mask = model.predict(x_tensor)\n",
    "    pr_mask = (pr_mask > p).squeeze().cpu().numpy()\n",
    "    file_name = os.path.join(PREDICTED, img_path.split('/')[-1])\n",
    "    cv2.imwrite(file_name, np.float32(pr_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sAf-eorPzhEn",
   "metadata": {
    "id": "sAf-eorPzhEn"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "detect_text.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
