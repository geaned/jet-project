{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character Error Rate (OCR vs Object Detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "metric = load_metric(\"cer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_cer_score(predictions_folder, gt_folder):\n",
    "    predictions, ground_truth = [], []\n",
    "\n",
    "    for filename in os.listdir(predictions_folder):\n",
    "        curr_preds, curr_gt = [], []\n",
    "        with open(os.path.join(predictions_folder, filename)) as f:\n",
    "            for line in f.readlines():\n",
    "                curr_preds.append(line.replace('\\n', ''))\n",
    "        with open(os.path.join(gt_folder, filename)) as f:\n",
    "            for line in f.readlines():\n",
    "                curr_gt.append(line.replace('\\n', ''))\n",
    "        if len(curr_preds) < len(curr_gt):\n",
    "            predictions.extend(['-'] * (len(curr_gt) - len(curr_preds)))\n",
    "        elif len(curr_preds) > len(curr_gt):\n",
    "            ground_truth.extend(['-'] * (len(curr_preds) - len(curr_gt)))\n",
    "        predictions.extend(curr_preds)\n",
    "        ground_truth.extend(curr_gt)\n",
    "    \n",
    "    cer_score = metric.compute(predictions=predictions, references=ground_truth)\n",
    "    return cer_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним результаты работы 2 пайплайнов: OCR и детекции отдельных цифр. Для этого посчитаем Character Error Rate (CER) для обоих подходов.\n",
    "\n",
    "Начнём с OCR:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При запуске пайплайна на 71 фотографии было отобрано и размечено 103 торца"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "OCR_PREDICTIONS_FOLDER = '/home/asya/studying/Проекты/serial_number_recognition/copy_OCR_pipeline/jet-project/strings'\n",
    "OCR_GROUND_TRUTH_FOLDER = '/home/asya/studying/Проекты/serial_number_recognition/copy_OCR_pipeline/jet-project/ground_truth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2749003984063745"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ocr_cer_score = get_cer_score(OCR_PREDICTIONS_FOLDER, OCR_GROUND_TRUTH_FOLDER)\n",
    "ocr_cer_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь пайплайн с детекцией отдельных цифр:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При запуске пайплайна на 71 фотографии было отобрано и размечено 129 торца"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "OD_PREDICTIONS_FOLDER = '/home/asya/studying/Проекты/serial_number_recognition/repo/jet-project/strings'\n",
    "OD_GROUND_TRUTH_FOLDER = '/home/asya/studying/Проекты/serial_number_recognition/repo/jet-project/ground_truth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35773026315789475"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "od_cer_score = get_cer_score(OD_PREDICTIONS_FOLDER, OD_GROUND_TRUTH_FOLDER)\n",
    "od_cer_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получаем, что на всех отобранных алгоритмами фотографиях значение ошибки меньше для OCR-пайплайна. Но это может быть связано ещё и с тем, что модель находит строчки с номерами не на всех фотографиях торцов (пайплайн с детекцией разметил больше прутков, чем OCR).\n",
    "\n",
    "Поэтому для полноты оценки дополнительно посчитаем значение CER:\n",
    "1. только на общих (пересекающихся) фотографиях\n",
    "2. на фотографиях хорошего качества (на взгляд) из первоначальной разбивки\n",
    "3. на фотографиях плохого качества"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## На общих фотографиях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_INTERSECTION = list(set(os.listdir(OCR_PREDICTIONS_FOLDER)) & set(os.listdir(OD_PREDICTIONS_FOLDER)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intersection_cer_score(predictions_folder, gt_folder):\n",
    "    predictions, ground_truth = [], []\n",
    "\n",
    "    for filename in IMG_INTERSECTION:\n",
    "        curr_preds, curr_gt = [], []\n",
    "        with open(os.path.join(predictions_folder, filename)) as f:\n",
    "            for line in f.readlines():\n",
    "                curr_preds.append(line.replace('\\n', ''))\n",
    "        with open(os.path.join(gt_folder, filename)) as f:\n",
    "            for line in f.readlines():\n",
    "                curr_gt.append(line.replace('\\n', ''))\n",
    "        if len(curr_preds) < len(curr_gt):\n",
    "            predictions.extend(['-'] * (len(curr_gt) - len(curr_preds)))\n",
    "        elif len(curr_preds) > len(curr_gt):\n",
    "            ground_truth.extend(['-'] * (len(curr_preds) - len(curr_gt)))\n",
    "        predictions.extend(curr_preds)\n",
    "        ground_truth.extend(curr_gt)\n",
    "    \n",
    "    cer_score = metric.compute(predictions=predictions, references=ground_truth)\n",
    "    return cer_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25311203319502074"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ocr_inter_cer_score = get_intersection_cer_score(OCR_PREDICTIONS_FOLDER, OCR_GROUND_TRUTH_FOLDER)\n",
    "ocr_inter_cer_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26997840172786175"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "od_inter_cer_score = get_intersection_cer_score(OD_PREDICTIONS_FOLDER, OD_GROUND_TRUTH_FOLDER)\n",
    "od_inter_cer_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На общих фотографиях OCR чуть лучше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## На фотографиях хорошего качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_appropriate_cer_score(predictions_folder, gt_folder):\n",
    "    predictions, ground_truth = [], []\n",
    "\n",
    "    for filename in os.listdir(predictions_folder):\n",
    "        if filename.startswith('IMG_17'):\n",
    "            curr_preds, curr_gt = [], []\n",
    "            with open(os.path.join(predictions_folder, filename)) as f:\n",
    "                for line in f.readlines():\n",
    "                    curr_preds.append(line.replace('\\n', ''))\n",
    "            with open(os.path.join(gt_folder, filename)) as f:\n",
    "                for line in f.readlines():\n",
    "                    curr_gt.append(line.replace('\\n', ''))\n",
    "            if len(curr_preds) < len(curr_gt):\n",
    "                predictions.extend(['-'] * (len(curr_gt) - len(curr_preds)))\n",
    "            elif len(curr_preds) > len(curr_gt):\n",
    "                ground_truth.extend(['-'] * (len(curr_preds) - len(curr_gt)))\n",
    "            predictions.extend(curr_preds)\n",
    "            ground_truth.extend(curr_gt)\n",
    "    \n",
    "    cer_score = metric.compute(predictions=predictions, references=ground_truth)\n",
    "    return cer_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.043795620437956206"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ocr_good_cer_score = get_appropriate_cer_score(OCR_PREDICTIONS_FOLDER, OCR_GROUND_TRUTH_FOLDER)\n",
    "ocr_good_cer_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0072992700729927005"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "od_good_cer_score = get_appropriate_cer_score(OD_PREDICTIONS_FOLDER, OD_GROUND_TRUTH_FOLDER)\n",
    "od_good_cer_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На \"хороших\" изображениях оба подхода отрабатывают почти идеально, но детекция отдельных цифр чуть лучше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## На фотографиях плохого качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bad_cer_score(predictions_folder, gt_folder):\n",
    "    predictions, ground_truth = [], []\n",
    "\n",
    "    for filename in os.listdir(predictions_folder):\n",
    "        if filename.startswith('IMG_6'):\n",
    "            curr_preds, curr_gt = [], []\n",
    "            with open(os.path.join(predictions_folder, filename)) as f:\n",
    "                for line in f.readlines():\n",
    "                    curr_preds.append(line.replace('\\n', ''))\n",
    "            with open(os.path.join(gt_folder, filename)) as f:\n",
    "                for line in f.readlines():\n",
    "                    curr_gt.append(line.replace('\\n', ''))\n",
    "            if len(curr_preds) < len(curr_gt):\n",
    "                predictions.extend(['-'] * (len(curr_gt) - len(curr_preds)))\n",
    "            elif len(curr_preds) > len(curr_gt):\n",
    "                ground_truth.extend(['-'] * (len(curr_preds) - len(curr_gt)))\n",
    "            predictions.extend(curr_preds)\n",
    "            ground_truth.extend(curr_gt)\n",
    "    \n",
    "    cer_score = metric.compute(predictions=predictions, references=ground_truth)\n",
    "    return cer_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4350758853288364"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ocr_bad_cer_score = get_bad_cer_score(OCR_PREDICTIONS_FOLDER, OCR_GROUND_TRUTH_FOLDER)\n",
    "ocr_bad_cer_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5366459627329192"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "od_bad_cer_score = get_bad_cer_score(OD_PREDICTIONS_FOLDER, OD_GROUND_TRUTH_FOLDER)\n",
    "od_bad_cer_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На изображениях плохого качества пайплайны отрабатывают заметно хуже. В этом случае OCR справляется лучше."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
